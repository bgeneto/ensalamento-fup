# Streamlit Caching Optimization Analysis

**Date:** 2025-10-23
**Scope:** System-wide review of caching opportunities
**Goal:** Identify high-impact, low-risk caching optimizations

---

## ‚úÖ Current State

**Already Cached:**
- `page_footer._get_footer_html()` - Footer HTML generation (recently optimized)

**Total Cache Usage:** 1 function

---

## üéØ High-Impact Caching Opportunities

### 1. **SigaaScheduleParser Constants** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Priority:** CRITICAL
**File:** `src/utils/sigaa_parser.py`
**Impact:** HIGH (used in every demand display, allocation, and suggestion calculation)

**Problem:**
- `SigaaScheduleParser` class instantiated repeatedly across pages
- Contains static dictionaries (`MAP_DAYS`, `MAP_SCHEDULE_TIMES`) that never change
- Currently recreated on EVERY function call in multiple modules

**Current Usage:**
```python
# In alloc_queue.py, allocation_assistant.py, Demanda.py, etc.
parser = SigaaScheduleParser()  # ‚ùå Recreated on every page load
```

**Solution:**
```python
# In src/utils/sigaa_parser.py
@st.cache_resource
def get_sigaa_parser() -> SigaaScheduleParser:
    """Get singleton SigaaScheduleParser instance (cached)."""
    return SigaaScheduleParser()

# Then replace all instantiations:
parser = get_sigaa_parser()  # ‚úÖ Cached singleton
```

**Benefits:**
- Eliminates repeated object creation
- Reduces memory footprint
- Speeds up all schedule parsing operations (used in 5+ pages)

**Risk:** NONE (pure utility class with no state)

---

### 2. **Database Lookup Dictionaries** ‚≠ê‚≠ê‚≠ê‚≠ê
**Priority:** HIGH
**Files:** Multiple pages and components
**Impact:** MEDIUM-HIGH (reduce DB queries during render cycles)

**Problem:**
Pages repeatedly build lookup dictionaries from DB for dropdowns/display:

```python
# In tab_rooms.py, Regras.py, etc.
with get_db_session() as session:
    predios = predio_repo.get_all()
    tipos_sala = tipo_sala_repo.get_all()

    # Build lookup dicts every render
    predio_options = {predio.id: predio.nome for predio in predios}  # ‚ùå
    tipo_sala_options = {ts.id: ts.nome for ts in tipos_sala}  # ‚ùå
```

**Solution:**
Create cached helper functions:

```python
# In src/utils/cache_helpers.py (new file)
import streamlit as st
from src.config.database import get_db_session
from src.repositories.predio import PredioRepository
from src.repositories.tipo_sala import TipoSalaRepository
from src.repositories.caracteristica import CaracteristicaRepository

@st.cache_data(ttl=300)  # 5-minute TTL (data changes infrequently)
def get_predio_options() -> dict[int, str]:
    """Get building ID->name mapping (cached)."""
    with get_db_session() as session:
        predios = PredioRepository(session).get_all()
        return {p.id: p.nome for p in predios}

@st.cache_data(ttl=300)
def get_tipo_sala_options() -> dict[int, str]:
    """Get room type ID->name mapping (cached)."""
    with get_db_session() as session:
        tipos = TipoSalaRepository(session).get_all()
        return {t.id: t.nome for t in tipos}

@st.cache_data(ttl=300)
def get_caracteristica_options() -> dict[int, str]:
    """Get characteristic ID->name mapping (cached)."""
    with get_db_session() as session:
        cars = CaracteristicaRepository(session).get_all()
        return {c.id: c.nome for c in cars}
```

**Usage:**
```python
# In pages
from src.utils.cache_helpers import get_predio_options, get_tipo_sala_options

predio_options = get_predio_options()  # ‚úÖ Cached for 5 minutes
tipo_sala_options = get_tipo_sala_options()  # ‚úÖ Cached
```

**Benefits:**
- Reduces DB queries by ~70% for reference data
- Faster page loads
- Consistent data across simultaneous page renders

**Risk:** LOW (reference data changes infrequently; 5-min TTL ensures freshness)

---

### 3. **Allocation Progress Metrics** ‚≠ê‚≠ê‚≠ê
**Priority:** MEDIUM
**File:** `pages/components/alloc_queue.py`
**Impact:** MEDIUM (expensive DB aggregation repeated on every queue render)

**Problem:**
```python
# In render_demand_queue()
progress = alloc_service.get_allocation_progress(semester_id)  # ‚ùå Expensive query every render
```

**Solution:**
```python
# In alloc_queue.py
@st.cache_data(ttl=10)  # 10-second TTL (updates frequently during allocation)
def _get_cached_progress(semester_id: int) -> dict:
    """Get allocation progress with short-term caching."""
    with get_db_session() as session:
        alloc_service = ManualAllocationService(session)
        return alloc_service.get_allocation_progress(semester_id)

# Then use:
progress = _get_cached_progress(semester_id)  # ‚úÖ Cached for 10 seconds
```

**Benefits:**
- Reduces DB query load during active allocation sessions
- Progress bar/metrics render instantly on page refresh

**Risk:** LOW (10-sec TTL balances performance vs. real-time updates)

---

### 4. **Semester Options List** ‚≠ê‚≠ê‚≠ê
**Priority:** MEDIUM
**Files:** Multiple pages with semester selectors
**Impact:** MEDIUM

**Problem:**
```python
# In Demanda.py, Aloca√ß√£o_Manual.py, etc.
with get_db_session() as session:
    sem_repo = SemestreRepository(session)
    semestres = sem_repo.get_all()  # ‚ùå Repeated on every page load
```

**Solution:**
```python
# In src/utils/cache_helpers.py
@st.cache_data(ttl=600)  # 10-minute TTL (semesters change rarely)
def get_semester_options() -> list[tuple[int, str]]:
    """Get semester options as (id, name) tuples (cached)."""
    with get_db_session() as session:
        semestres = SemestreRepository(session).get_all()
        return [(s.id, s.nome) for s in semestres]
```

**Benefits:**
- Eliminates redundant semester queries across pages
- Consistent semester list during user session

**Risk:** MINIMAL (semesters rarely change; 10-min TTL acceptable)

---

### 5. **Rule Evaluation Functions** ‚≠ê‚≠ê
**Priority:** LOW-MEDIUM
**File:** `pages/4_üìå_Regras.py`
**Impact:** LOW (pure utility functions)

**Problem:**
Helper functions like `_generate_rule_description()` and `format_rule_display()` are called repeatedly with same inputs.

**Solution:**
```python
@st.cache_data
def _generate_rule_description(
    rule_type: str,
    disc_code: str,
    sala_id: Optional[int],
    tipo_sala_id: Optional[int],
    caracteristica: str,
    prioridade: int,
    salas_dict: dict,
    tipos_sala_dict: dict,
) -> str:
    """Generate rule description (cached - pure function)."""
    # ... existing logic
```

**Benefits:**
- Faster rule list rendering
- Reduced CPU cycles for string formatting

**Risk:** NONE (pure functions with deterministic outputs)

---

## ‚ùå Anti-Patterns to Avoid

### 1. **DO NOT Cache UI Rendering Functions**
```python
# ‚ùå WRONG - Functions with side effects (st.markdown, st.write, etc.)
@st.cache_data
def render_demand_queue(...):
    st.header("...")  # Side effect!
    st.dataframe(...)  # Side effect!
```

**Why:** Streamlit cache returns stored values; UI elements won't render after first call.

---

### 2. **DO NOT Cache Database Sessions**
```python
# ‚ùå WRONG - Sessions are stateful and not thread-safe
@st.cache_resource
def get_cached_session():
    return get_db_session()  # DON'T DO THIS
```

**Why:** SQLAlchemy sessions are not thread-safe; can cause data corruption.

---

### 3. **DO NOT Cache Large DataFrames Without TTL**
```python
# ‚ùå RISKY - No TTL on data that changes frequently
@st.cache_data  # Missing ttl parameter!
def get_all_demands():
    # Returns 1000+ row DataFrame
```

**Why:** Stale data shown to users; memory bloat from storing large objects.

---

## üìã Implementation Checklist

### Phase 1: Quick Wins (1-2 hours) ‚úÖ COMPLETED
- [x] Create `src/utils/cache_helpers.py`
- [x] Implement `get_sigaa_parser()` cached singleton
- [x] Replace all `SigaaScheduleParser()` instantiations with cached version
- [x] Add cached lookup functions: `get_predio_options()`, `get_tipo_sala_options()`, `get_caracteristica_options()`
- [x] Update `tab_rooms.py`, `tab_buildings.py`, `Regras.py` to use cached lookups

### Phase 2: Medium Impact (2-3 hours) ‚úÖ COMPLETED
- [x] Cache `get_semester_options()` helper
- [x] Update all pages with semester selectors to use cached version (Demanda, Ensalamento, Aloca√ß√£o Manual)
- [x] Create `test_cache.py` validation script (622.8x speedup verified)
- [x] Document implementation in `PHASE_2_SEMESTER_CACHE_SUMMARY.md`
- [ ] Add cached `_get_cached_progress()` in `alloc_queue.py` (deferred to Phase 3)
- [ ] Test TTL behavior (confirm cache invalidation works)

### Phase 3: Polish (1 hour)
- [ ] Cache allocation progress metrics (`_get_cached_progress()` with 10-sec TTL)
- [ ] Cache pure utility functions in `Regras.py`
- [ ] Add cache monitoring metrics (optional: `st.sidebar.write(st.cache_data.clear())` for debugging)
- [ ] Document caching patterns in `CLAUDE.md` for future development

---

## üß™ Testing Strategy

### 1. **Verify Cache Hits**
```python
# Add temporary debug code
import streamlit as st

st.sidebar.write("Cache Stats:")
st.sidebar.write(st.cache_data._cache_info())  # Shows hits/misses
```

### 2. **Test TTL Expiration**
- Load page ‚Üí note timestamp
- Make DB change (e.g., add new building)
- Refresh page immediately ‚Üí should show old data (cached)
- Wait for TTL ‚Üí refresh ‚Üí should show new data

### 3. **Performance Benchmarking**
```python
import time

start = time.time()
result = get_predio_options()  # First call (cache miss)
print(f"Uncached: {time.time() - start:.3f}s")

start = time.time()
result = get_predio_options()  # Second call (cache hit)
print(f"Cached: {time.time() - start:.3f}s")
```

---

## üìä Expected Performance Gains

| Optimization       | Pages Affected | Expected Speedup | Risk Level |
| ------------------ | -------------- | ---------------- | ---------- |
| Cached SigaaParser | 5+ pages       | 10-20ms per page | None       |
| Cached Lookups     | 4 pages        | 20-50ms per page | Low        |
| Cached Progress    | Manual Alloc   | 50-100ms         | Low        |
| Cached Semesters   | 3 pages        | 10-20ms per page | Minimal    |

**Total Expected Improvement:** 100-300ms faster page loads (20-40% reduction in DB queries)

---

## üîß Maintenance Guidelines

1. **TTL Selection Rules:**
   - Static data (constants): No TTL or very long (3600s)
   - Reference data (buildings, types): 300s (5 min)
   - Aggregated metrics: 10-60s
   - Transactional data: DO NOT CACHE

2. **Cache Invalidation:**
   - Add manual clear buttons for admins: `st.cache_data.clear()`
   - Consider event-based invalidation for critical data

3. **Monitoring:**
   - Log cache hit rates in production
   - Track memory usage (large cached objects)

---

## üö´ What NOT to Cache

1. ‚ùå Functions that call `st.*` UI methods
2. ‚ùå Database sessions or ORM objects
3. ‚ùå User-specific data (unless keyed by user ID)
4. ‚ùå Data that changes multiple times per minute
5. ‚ùå Large DataFrames without memory consideration

---

## üìö References

- [Streamlit Caching Guide](https://docs.streamlit.io/library/advanced-features/caching)
- [st.cache_data vs st.cache_resource](https://docs.streamlit.io/library/advanced-features/caching#st-cache_data-vs-st-cache_resource)
- Project: `.github/copilot-instructions.md` (Streamlit Messages & st.rerun() Pattern)

---

**Next Steps:** Review Phase 1 checklist ‚Üí implement ‚Üí test ‚Üí measure ‚Üí iterate.
